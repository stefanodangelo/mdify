{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"MDify Welcome to the official documentation of MDify \ud83e\udd17 Contents Reference : contains documentation and references to the source code. Usage : contains examples of how to use the library. 1. Introduction MDify is a powerful Python library for converting PDFs (or image-based documents) into clean, structured Markdown. 2. Features \u2714\ufe0f Handles complex layouts - Extracts text, tables, and visual elements with precision \ud83d\uddbc\ufe0f Preserves images & charts - Gives the option to save and reuse extracted visuals for Computer Vision tasks \ud83c\udfaf Optimized for accuracy - Combines layout detection and OCR to extract text from documents \ud83e\udd16 Preprocessing for LLM applications - Converts documents to Markdown, which is popular for LLM training and fine-tuning tasks \ud83d\udee0\ufe0f Debug mode - Save intermediate document elements as images for analysis Notes : - The first run will take ~2 minutes to download the necessary models. - Currently, MDify can only handle PDFs and images (such as text extracts, document scans, etc.). Therefore, please make sure that your documents meet the requirements in order for the tool to work best. - Diagrams are not supported yet, therefore if you use the DESCRIBED write mode they may be analyzed incorrectly. 3. Contributing MDify is an independent, open-source project developed and maintained by a passionate developer. Your support is highly valued, and any contributions \u2014 whether through issues, bug reports, feature requests, or pull requests \u2014 are more than welcome! Here is the link to the GitHub repo . 4. License This project is licensed under the Creative Commons Attribution-NonCommercial 4.0 International License .","title":"Home"},{"location":"#mdify","text":"Welcome to the official documentation of MDify \ud83e\udd17","title":"MDify"},{"location":"#contents","text":"Reference : contains documentation and references to the source code. Usage : contains examples of how to use the library.","title":"Contents"},{"location":"#1-introduction","text":"MDify is a powerful Python library for converting PDFs (or image-based documents) into clean, structured Markdown.","title":"1. Introduction"},{"location":"#2-features","text":"\u2714\ufe0f Handles complex layouts - Extracts text, tables, and visual elements with precision \ud83d\uddbc\ufe0f Preserves images & charts - Gives the option to save and reuse extracted visuals for Computer Vision tasks \ud83c\udfaf Optimized for accuracy - Combines layout detection and OCR to extract text from documents \ud83e\udd16 Preprocessing for LLM applications - Converts documents to Markdown, which is popular for LLM training and fine-tuning tasks \ud83d\udee0\ufe0f Debug mode - Save intermediate document elements as images for analysis Notes : - The first run will take ~2 minutes to download the necessary models. - Currently, MDify can only handle PDFs and images (such as text extracts, document scans, etc.). Therefore, please make sure that your documents meet the requirements in order for the tool to work best. - Diagrams are not supported yet, therefore if you use the DESCRIBED write mode they may be analyzed incorrectly.","title":"2. Features"},{"location":"#3-contributing","text":"MDify is an independent, open-source project developed and maintained by a passionate developer. Your support is highly valued, and any contributions \u2014 whether through issues, bug reports, feature requests, or pull requests \u2014 are more than welcome! Here is the link to the GitHub repo .","title":"3. Contributing"},{"location":"#4-license","text":"This project is licensed under the Creative Commons Attribution-NonCommercial 4.0 International License .","title":"4. License"},{"location":"reference/","text":"Reference mdify.src.parsers DocumentParser A class that processes documents (PDFs or images) to extract their content and save artifacts like images, tables, charts, and formulas. Attributes: save_folder ( str ) \u2013 Folder where the processed documents will be saved. extract_metadata ( bool ) \u2013 Flag to indicate if metadata should be extracted. metadata_filename ( str ) \u2013 The filename for saving metadata. save_artifacts ( OutputArtifact ) \u2013 Specifies the types of artifacts to save. debug ( bool ) \u2013 Flag to control debug mode. If True , it will keep temporary folders containing all pages and all elements extracted in each page in image format. PIL_supported_formats ( list ) \u2013 List of supported image formats by PIL. detector ( LayoutDetector ) \u2013 Layout detection object. extractor ( ContentExtractor ) \u2013 Content extraction object. Methods: parse_directory \u2013 str, **kwargs): Parses multiple documents from a directory. parse \u2013 Union[str, bytes], document_name: str = None, document_type: str = None, **kwargs): Parses a single document and processes it. metadata property Returns: dict \u2013 A dictionary where the keys are the paths to the output files and the values are the metadata objects associated with each document. metadata_paths property Returns: dict \u2013 A dictionary with the paths to the output files as keys and the paths to the metadata files as values. output_files property Returns: dict \u2013 A dictionary with the paths to the output files as keys and the corresponding file objects as values. output_files_paths property Returns: list \u2013 List of file paths to the files generated for each processed document. cleanup() Deletes the directory where processed documents and artifacts are stored and all its contents. parse(document, document_name=None, document_type=None, **kwargs) Converts a document into Markdown. Parameters: document ( Union [ str , bytes ] ) \u2013 Document to be parsed. If a string, it is the path to the document. If bytes, document_type and document_name must be specified. document_name ( str , default: None ) \u2013 Name of document if document is an instance of bytes. Defaults to None. document_type ( str , default: None ) \u2013 Type of document if document is an instance of bytes. Defaults to None. **kwargs \u2013 Additional keyword arguments passed to the rendering function and the extractor for each element. Raises: ValueError \u2013 If document_name and document_type are not provided when parsing bytes. parse_directory(documents_dir, **kwargs) Parses multiple documents from a given directory. Parameters: documents_dir ( str ) \u2013 Directory containing documents to be parsed. **kwargs \u2013 Additional arguments passed to the parse method. mdify.src.layout LayoutDetector Detects and organizes layout elements from a document page using a pre-trained YOLO model. This class is designed to process pages containing elements such as titles, headers, footnotes, and pictures, allowing for efficient extraction, sorting, and saving of these components. Attributes: model \u2013 Pre-trained YOLO model for layout detection. config ( dict ) \u2013 Configuration settings for the layout detection model. filename_separator ( str ) \u2013 Separator used for naming cropped element files. picture_classifier ( PictureClassifier ) \u2013 Classifier for recognizing picture types in the layout. __custom_sort(elem) Sorts layout elements based on their vertical and horizontal positions on the page. Elements are ordered first from top-to-bottom (y1) and then from left-to-right (x1). To support multicolumn formats, elements on the x-axis are assigned a higher weight the more they are on the right of the page. This way, elements at the bottom of the page can still be correctly positioned. Each element is also given a priority based on the type of element it is (e.g. footnotes must go at the bottom, headers at the top). Parameters: elem ( tuple ) \u2013 A tuple containing a bounding box, label, and other metadata. Returns: tuple \u2013 Sorting key based on element type priority and position. __get_num_of_columns(x_positions, page_width, num_bins=10, density_threshold=0.5) Estimates the number of columns in a document page based on the density of x-coordinates. Parameters: x_positions ( Iterable [ float ] ) \u2013 X-coordinates of detected bounding boxes. page_width ( float ) \u2013 Width of the page in pixels. num_bins ( Optional [ int ] , default: 10 ) \u2013 Number of bins for dividing the page width. Default is 10. density_threshold ( Optional [ float ] , default: 0.5 ) \u2013 Threshold for determining high-density regions. Default is 0.5. Returns: int ( int ) \u2013 Number of columns detected in the page. detect(image_path, page_nr, output_dir='', **kwargs) Detects and extracts layout elements from a document page image. Parameters: image_path ( str ) \u2013 Path to the input image of the document page. page_nr ( str ) \u2013 Page number used for naming output files. output_dir ( Optional [ str ] , default: '' ) \u2013 Directory where extracted elements will be saved. Default is an empty string. **kwargs \u2013 Additional parameters for the YOLO model. Returns: List \u2013 A list of detected layout elements if output_dir is not provided. Otherwise, saves elements to the specified directory. render(image_path, output_dir, **kwargs) Renders annotated layout elements on the input document page image. Parameters: image_path ( str ) \u2013 Path to the input image of the document page. output_dir ( str ) \u2013 Directory where the annotated image will be saved. **kwargs \u2013 Additional parameters for the detection process. Saves Annotated image with bounding boxes and labels drawn over the original image. mdify.src.models ChartDeplotModel Bases: HuggingFaceModel Specialized Hugging Face model for extracting data from charts. Attributes: placeholder ( str ) \u2013 Placeholder token used in the model's output. separator ( str ) \u2013 Separator used in the model's output. FormulaExtractionModel Bases: HuggingFaceModel Specialized model for extracting mathematical formulas from images. HuggingFaceModel A generic wrapper for Hugging Face models that supports text and vision-based predictions. Attributes: processor \u2013 Preprocessor for the specific Hugging Face model. model \u2013 Pretrained Hugging Face model for predictions. config ( dict ) \u2013 Additional configurations for model generation. prompt ( str ) \u2013 Text prompt to be used during prediction (if applicable). use_pixel_values ( bool ) \u2013 Whether to use pixel values instead of text tokens. predict(image_path) Generates a prediction for the input image using the Hugging Face model. Parameters: image_path ( str ) \u2013 Path to the input image. Returns: \u2013 The processed output from the model's predictions. ImageCaptioningModel Bases: HuggingFaceModel Hugging Face model for generating captions for images. PictureClassifier Classifies images into categories such as \"Picture\" or \"Chart\" using a pretrained Swin Transformer model. Attributes: model ( SwinForImageClassification ) \u2013 Pretrained Swin model for image classification. device ( device ) \u2013 Device to perform computations, either CPU or GPU. transform ( Compose ) \u2013 Preprocessing transformations for input images. id2class ( dict ) \u2013 Mapping of class indices to class names. classify(image) Classifies an input image into predefined categories, using GPU if available. Parameters: image ( str | ndarray ) \u2013 Path to the image or an image in the form of a NumPy array. Returns: int ( int ) \u2013 Predicted class index of the image. mdify.src.ocr OCR Abstract base class for OCR processing. It provides a common interface and workflow for derived OCR classes. Methods: process \u2013 Main method to process an image and perform OCR. process_results \u2013 Abstract method to be implemented by subclasses for processing OCR results. process(image_path, save_dir, filename, save_artifacts=OutputArtifact.NONE, write_mode=WriteMode.EMBEDDED, debug=False, **kwargs) Processes the image and initializes OCR attributes. Parameters: image_path ( str ) \u2013 Path to the input image. save_dir ( str ) \u2013 Directory to save OCR artifacts. filename ( str ) \u2013 Base filename for saving artifacts. save_artifacts ( Optional [ OutputArtifact ] , default: NONE ) \u2013 Specifies which artifacts to save. write_mode ( Optional [ WriteMode ] , default: EMBEDDED ) \u2013 Determines the output format of extracted text. debug ( Optional [ bool ] , default: False ) \u2013 If True, saves a debug image. **kwargs \u2013 Additional arguments for customization. Raises: Exception \u2013 If the image cannot be processed. process_results(**kwargs) abstractmethod Abstract method to process OCR results. Subclasses must implement this method. PictureRecognizer Bases: OCR Class for recognizing and processing image-based data such as charts, captions, or formulas. Attributes: chart_qa_model \u2013 Model for extracting data from charts. captioning_model \u2013 Model for generating captions for images. formula_extraction_model \u2013 Model for extracting mathematical formulas. __make_save_path(extension=IMAGES_SAVE_EXTENSION, **kwargs) Creates the save path for the image artifact. __save_image(**kwargs) Saves the processed image. process_results(**kwargs) Processes the image results based on its type (chart, formula, or general image). Parameters: save_dir ( str ) \u2013 Directory to save OCR artifacts. TableRecognizer Bases: OCR Class for recognizing and organizing table data from images. Attributes: config ( dict ) \u2013 Configuration for table OCR model. model ( PaddleOCR ) \u2013 Instance of PaddleOCR model. __find_column_boundaries(bboxes, tolerance=10) Finds boundaries of table columns based on bounding boxes. Parameters: bboxes ( Iterable [ Iterable [ float ]] ) \u2013 List of bounding boxes. tolerance ( int , default: 10 ) \u2013 Margin of error in pixels for boundary grouping. Returns: Iterable [ float ] \u2013 Iterable[float]: Sorted list of column boundaries. __find_header(column_boundaries, bboxes, tolerance=10) Identifies the row index where the table header ends. Parameters: column_boundaries ( Iterable [ float ] ) \u2013 List of column boundaries. bboxes ( ndarray ) \u2013 Array of bounding boxes. tolerance ( int , default: 10 ) \u2013 Margin of error in pixels for header detection. Returns: int ( int ) \u2013 Row index where the header ends. ocr(img, cls=True, **kwargs) Performs OCR on the provided image and extracts table text and bounding boxes. Parameters: img ( ndarray ) \u2013 Input image as a NumPy array. cls ( bool , default: True ) \u2013 Whether to use classification. **kwargs \u2013 Additional arguments passed to the OCR model. process_results(**kwargs) Organizes text into table columns based on bounding box x-coordinates and returns a DataFrame. Ensures every column is populated with either text or None for all rows. Parameters: row_tolerance ( int ) \u2013 Margin of error in pixels to assign elements to the correct row. col_tolerance ( int ) \u2013 Margin of error in pixels to assign elements to the correct column. render(img, save_full_path, font_path='../utils/simfang.ttf', **kwargs) Renders the recognized data onto the input image and saves it. Parameters: img ( ndarray | str ) \u2013 Input image as an array or path. save_full_path ( str ) \u2013 Full path to save the rendered image. font_path ( str , default: '../utils/simfang.ttf' ) \u2013 Path to the font used for rendering. **kwargs \u2013 Additional arguments for rendering. TextRecognizer Bases: OCR Class for recognizing text from images using OCR. Two different models are used for headers and paragraphs as it has been observed that using only one of them for both yields less accurate results. Attributes: paragraph_model_config ( dict ) \u2013 Configuration for paragraph-level OCR. header_reader ( Reader ) \u2013 Reader instance for header-level OCR. det_processor, ( ( det_model , rec_model , rec_processor ) ) \u2013 Components for OCR processing. default_element_type ( str ) \u2013 Default type of element to process ('paragraph'). process_results(**kwargs) Processes OCR results based on the specified element type (paragraph or header). Parameters: element_to_process ( str ) \u2013 either 'header' or 'paragraph'. mdify.src.output OutputArtifact Bases: Enum Enum representing the types of artifacts to be saved. Types NONE (int): No artifacts are saved. ONLY_PICTURES (int): Only images are saved. ONLY_TABLES (int): Only tables are saved. ONLY_CHARTS (int): Only charts are saved. ONLY_FORMULAS (int): Only formulas are saved. PICTURES_AND_TABLES (int): Both images and tables are saved. PICTURES_AND_CHARTS (int): Both images and charts are saved. PICTURES_AND_FORMULAS (int): Both images and formulas are saved. TABLES_AND_CHARTS (int): Both tables and charts are saved. TABLES_AND_FORMULAS (int): Both tables and formulas are saved. CHARTS_AND_FORMULAS (int): Both charts and formulas are saved. PICTURES_TABLES_AND_CHARTS (int): Images, tables, and charts are saved. PICTURES_TABLES_AND_FORMULAS (int): Images, tables, and formulas are saved. PICTURES_CHARTS_AND_FORMULAS (int): Images, charts, and formulas are saved. TABLES_CHARTS_AND_FORMULAS (int): Tables, charts, and formulas are saved. ALL (int): All artifacts (images, tables, charts, formulas) are saved. OutputWriter Handles the process of writing content and optionally saving specified types of artifacts. Methods: write \u2013 str, save_dir: str, filename: str): Writes the content to a file in the specified directory, creating the directory if needed. write(content, save_dir, filename) staticmethod Writes the content to a markdown file in the specified directory. Parameters: content ( str ) \u2013 The content to write to the file. save_dir ( str ) \u2013 Directory where the file will be saved. filename ( str ) \u2013 Name of the file (without extension). WriteMode Bases: Enum Enum representing the modes for writing content with embedded or referenced artifacts. Modes EMBEDDED (int): Artifacts (e.g., images, tables) are directly embedded in the output content. PLACEHOLDER (int): Placeholders for artifacts are added in the output content, requiring external references. DESCRIBED (int): Artifacts are described textually, without direct embedding or placeholders. mdify.src.extractors ContentExtractor Extracts content from a document image based on specified types such as text, tables, pictures, and more. This class delegates extraction tasks to specialized recognizers for text, tables, and pictures. Attributes: text_recognizer ( TextRecognizer ) \u2013 Recognizer for extracting textual elements. table_recognizer ( TableRecognizer ) \u2013 Recognizer for extracting table elements. picture_recognizer ( PictureRecognizer ) \u2013 Recognizer for extracting picture elements. extract(image_path, extract_type, **kwargs) Method factory that extracts content from the specified image based on the type of element requested. Parameters: image_path ( str ) \u2013 Path to the input image of the document. extract_type ( str ) \u2013 Type of content to extract (e.g., 'text', 'table', 'picture', etc.). **kwargs \u2013 Additional parameters for the specific extraction method. Returns: str ( str ) \u2013 Extracted content as a string. mdify.src.utils convert_image_to_pdf(image_path, pdf_path) Converts an image file to a PDF. Parameters: image_path ( str ) \u2013 Path to the input image file. pdf_path ( str ) \u2013 Path to save the output PDF file. convert_to_jpeg(im) Converts an image to JPEG format. Parameters: im ( Image ) \u2013 The input image. Returns: PIL.Image: The converted image in JPEG format. get_filename(path, include_extension=False) Extracts the filename from a given path. Parameters: path ( str ) \u2013 The full path of the file. include_extension ( bool , default: False ) \u2013 Whether to include the file extension. Defaults to False. Returns: str: The extracted filename. open_image(img, to_numpy=False) Opens an image file or array, converting it to JPEG format if necessary. Parameters: img ( str | ndarray ) \u2013 Path to the image file or an image array. to_numpy ( bool , default: False ) \u2013 Whether to return the image as a NumPy array. Defaults to False. Returns: Union[np.ndarray, PIL.Image]: The opened image.","title":"Reference"},{"location":"reference/#reference","text":"","title":"Reference"},{"location":"reference/#mdify.src.parsers","text":"","title":"parsers"},{"location":"reference/#mdify.src.parsers.DocumentParser","text":"A class that processes documents (PDFs or images) to extract their content and save artifacts like images, tables, charts, and formulas. Attributes: save_folder ( str ) \u2013 Folder where the processed documents will be saved. extract_metadata ( bool ) \u2013 Flag to indicate if metadata should be extracted. metadata_filename ( str ) \u2013 The filename for saving metadata. save_artifacts ( OutputArtifact ) \u2013 Specifies the types of artifacts to save. debug ( bool ) \u2013 Flag to control debug mode. If True , it will keep temporary folders containing all pages and all elements extracted in each page in image format. PIL_supported_formats ( list ) \u2013 List of supported image formats by PIL. detector ( LayoutDetector ) \u2013 Layout detection object. extractor ( ContentExtractor ) \u2013 Content extraction object. Methods: parse_directory \u2013 str, **kwargs): Parses multiple documents from a directory. parse \u2013 Union[str, bytes], document_name: str = None, document_type: str = None, **kwargs): Parses a single document and processes it.","title":"DocumentParser"},{"location":"reference/#mdify.src.parsers.DocumentParser.metadata","text":"Returns: dict \u2013 A dictionary where the keys are the paths to the output files and the values are the metadata objects associated with each document.","title":"metadata"},{"location":"reference/#mdify.src.parsers.DocumentParser.metadata_paths","text":"Returns: dict \u2013 A dictionary with the paths to the output files as keys and the paths to the metadata files as values.","title":"metadata_paths"},{"location":"reference/#mdify.src.parsers.DocumentParser.output_files","text":"Returns: dict \u2013 A dictionary with the paths to the output files as keys and the corresponding file objects as values.","title":"output_files"},{"location":"reference/#mdify.src.parsers.DocumentParser.output_files_paths","text":"Returns: list \u2013 List of file paths to the files generated for each processed document.","title":"output_files_paths"},{"location":"reference/#mdify.src.parsers.DocumentParser.cleanup","text":"Deletes the directory where processed documents and artifacts are stored and all its contents.","title":"cleanup"},{"location":"reference/#mdify.src.parsers.DocumentParser.parse","text":"Converts a document into Markdown. Parameters: document ( Union [ str , bytes ] ) \u2013 Document to be parsed. If a string, it is the path to the document. If bytes, document_type and document_name must be specified. document_name ( str , default: None ) \u2013 Name of document if document is an instance of bytes. Defaults to None. document_type ( str , default: None ) \u2013 Type of document if document is an instance of bytes. Defaults to None. **kwargs \u2013 Additional keyword arguments passed to the rendering function and the extractor for each element. Raises: ValueError \u2013 If document_name and document_type are not provided when parsing bytes.","title":"parse"},{"location":"reference/#mdify.src.parsers.DocumentParser.parse_directory","text":"Parses multiple documents from a given directory. Parameters: documents_dir ( str ) \u2013 Directory containing documents to be parsed. **kwargs \u2013 Additional arguments passed to the parse method.","title":"parse_directory"},{"location":"reference/#mdify.src.layout","text":"","title":"layout"},{"location":"reference/#mdify.src.layout.LayoutDetector","text":"Detects and organizes layout elements from a document page using a pre-trained YOLO model. This class is designed to process pages containing elements such as titles, headers, footnotes, and pictures, allowing for efficient extraction, sorting, and saving of these components. Attributes: model \u2013 Pre-trained YOLO model for layout detection. config ( dict ) \u2013 Configuration settings for the layout detection model. filename_separator ( str ) \u2013 Separator used for naming cropped element files. picture_classifier ( PictureClassifier ) \u2013 Classifier for recognizing picture types in the layout.","title":"LayoutDetector"},{"location":"reference/#mdify.src.layout.LayoutDetector.__custom_sort","text":"Sorts layout elements based on their vertical and horizontal positions on the page. Elements are ordered first from top-to-bottom (y1) and then from left-to-right (x1). To support multicolumn formats, elements on the x-axis are assigned a higher weight the more they are on the right of the page. This way, elements at the bottom of the page can still be correctly positioned. Each element is also given a priority based on the type of element it is (e.g. footnotes must go at the bottom, headers at the top). Parameters: elem ( tuple ) \u2013 A tuple containing a bounding box, label, and other metadata. Returns: tuple \u2013 Sorting key based on element type priority and position.","title":"__custom_sort"},{"location":"reference/#mdify.src.layout.LayoutDetector.__get_num_of_columns","text":"Estimates the number of columns in a document page based on the density of x-coordinates. Parameters: x_positions ( Iterable [ float ] ) \u2013 X-coordinates of detected bounding boxes. page_width ( float ) \u2013 Width of the page in pixels. num_bins ( Optional [ int ] , default: 10 ) \u2013 Number of bins for dividing the page width. Default is 10. density_threshold ( Optional [ float ] , default: 0.5 ) \u2013 Threshold for determining high-density regions. Default is 0.5. Returns: int ( int ) \u2013 Number of columns detected in the page.","title":"__get_num_of_columns"},{"location":"reference/#mdify.src.layout.LayoutDetector.detect","text":"Detects and extracts layout elements from a document page image. Parameters: image_path ( str ) \u2013 Path to the input image of the document page. page_nr ( str ) \u2013 Page number used for naming output files. output_dir ( Optional [ str ] , default: '' ) \u2013 Directory where extracted elements will be saved. Default is an empty string. **kwargs \u2013 Additional parameters for the YOLO model. Returns: List \u2013 A list of detected layout elements if output_dir is not provided. Otherwise, saves elements to the specified directory.","title":"detect"},{"location":"reference/#mdify.src.layout.LayoutDetector.render","text":"Renders annotated layout elements on the input document page image. Parameters: image_path ( str ) \u2013 Path to the input image of the document page. output_dir ( str ) \u2013 Directory where the annotated image will be saved. **kwargs \u2013 Additional parameters for the detection process. Saves Annotated image with bounding boxes and labels drawn over the original image.","title":"render"},{"location":"reference/#mdify.src.models","text":"","title":"models"},{"location":"reference/#mdify.src.models.ChartDeplotModel","text":"Bases: HuggingFaceModel Specialized Hugging Face model for extracting data from charts. Attributes: placeholder ( str ) \u2013 Placeholder token used in the model's output. separator ( str ) \u2013 Separator used in the model's output.","title":"ChartDeplotModel"},{"location":"reference/#mdify.src.models.FormulaExtractionModel","text":"Bases: HuggingFaceModel Specialized model for extracting mathematical formulas from images.","title":"FormulaExtractionModel"},{"location":"reference/#mdify.src.models.HuggingFaceModel","text":"A generic wrapper for Hugging Face models that supports text and vision-based predictions. Attributes: processor \u2013 Preprocessor for the specific Hugging Face model. model \u2013 Pretrained Hugging Face model for predictions. config ( dict ) \u2013 Additional configurations for model generation. prompt ( str ) \u2013 Text prompt to be used during prediction (if applicable). use_pixel_values ( bool ) \u2013 Whether to use pixel values instead of text tokens.","title":"HuggingFaceModel"},{"location":"reference/#mdify.src.models.HuggingFaceModel.predict","text":"Generates a prediction for the input image using the Hugging Face model. Parameters: image_path ( str ) \u2013 Path to the input image. Returns: \u2013 The processed output from the model's predictions.","title":"predict"},{"location":"reference/#mdify.src.models.ImageCaptioningModel","text":"Bases: HuggingFaceModel Hugging Face model for generating captions for images.","title":"ImageCaptioningModel"},{"location":"reference/#mdify.src.models.PictureClassifier","text":"Classifies images into categories such as \"Picture\" or \"Chart\" using a pretrained Swin Transformer model. Attributes: model ( SwinForImageClassification ) \u2013 Pretrained Swin model for image classification. device ( device ) \u2013 Device to perform computations, either CPU or GPU. transform ( Compose ) \u2013 Preprocessing transformations for input images. id2class ( dict ) \u2013 Mapping of class indices to class names.","title":"PictureClassifier"},{"location":"reference/#mdify.src.models.PictureClassifier.classify","text":"Classifies an input image into predefined categories, using GPU if available. Parameters: image ( str | ndarray ) \u2013 Path to the image or an image in the form of a NumPy array. Returns: int ( int ) \u2013 Predicted class index of the image.","title":"classify"},{"location":"reference/#mdify.src.ocr","text":"","title":"ocr"},{"location":"reference/#mdify.src.ocr.OCR","text":"Abstract base class for OCR processing. It provides a common interface and workflow for derived OCR classes. Methods: process \u2013 Main method to process an image and perform OCR. process_results \u2013 Abstract method to be implemented by subclasses for processing OCR results.","title":"OCR"},{"location":"reference/#mdify.src.ocr.OCR.process","text":"Processes the image and initializes OCR attributes. Parameters: image_path ( str ) \u2013 Path to the input image. save_dir ( str ) \u2013 Directory to save OCR artifacts. filename ( str ) \u2013 Base filename for saving artifacts. save_artifacts ( Optional [ OutputArtifact ] , default: NONE ) \u2013 Specifies which artifacts to save. write_mode ( Optional [ WriteMode ] , default: EMBEDDED ) \u2013 Determines the output format of extracted text. debug ( Optional [ bool ] , default: False ) \u2013 If True, saves a debug image. **kwargs \u2013 Additional arguments for customization. Raises: Exception \u2013 If the image cannot be processed.","title":"process"},{"location":"reference/#mdify.src.ocr.OCR.process_results","text":"Abstract method to process OCR results. Subclasses must implement this method.","title":"process_results"},{"location":"reference/#mdify.src.ocr.PictureRecognizer","text":"Bases: OCR Class for recognizing and processing image-based data such as charts, captions, or formulas. Attributes: chart_qa_model \u2013 Model for extracting data from charts. captioning_model \u2013 Model for generating captions for images. formula_extraction_model \u2013 Model for extracting mathematical formulas.","title":"PictureRecognizer"},{"location":"reference/#mdify.src.ocr.PictureRecognizer.__make_save_path","text":"Creates the save path for the image artifact.","title":"__make_save_path"},{"location":"reference/#mdify.src.ocr.PictureRecognizer.__save_image","text":"Saves the processed image.","title":"__save_image"},{"location":"reference/#mdify.src.ocr.PictureRecognizer.process_results","text":"Processes the image results based on its type (chart, formula, or general image). Parameters: save_dir ( str ) \u2013 Directory to save OCR artifacts.","title":"process_results"},{"location":"reference/#mdify.src.ocr.TableRecognizer","text":"Bases: OCR Class for recognizing and organizing table data from images. Attributes: config ( dict ) \u2013 Configuration for table OCR model. model ( PaddleOCR ) \u2013 Instance of PaddleOCR model.","title":"TableRecognizer"},{"location":"reference/#mdify.src.ocr.TableRecognizer.__find_column_boundaries","text":"Finds boundaries of table columns based on bounding boxes. Parameters: bboxes ( Iterable [ Iterable [ float ]] ) \u2013 List of bounding boxes. tolerance ( int , default: 10 ) \u2013 Margin of error in pixels for boundary grouping. Returns: Iterable [ float ] \u2013 Iterable[float]: Sorted list of column boundaries.","title":"__find_column_boundaries"},{"location":"reference/#mdify.src.ocr.TableRecognizer.__find_header","text":"Identifies the row index where the table header ends. Parameters: column_boundaries ( Iterable [ float ] ) \u2013 List of column boundaries. bboxes ( ndarray ) \u2013 Array of bounding boxes. tolerance ( int , default: 10 ) \u2013 Margin of error in pixels for header detection. Returns: int ( int ) \u2013 Row index where the header ends.","title":"__find_header"},{"location":"reference/#mdify.src.ocr.TableRecognizer.ocr","text":"Performs OCR on the provided image and extracts table text and bounding boxes. Parameters: img ( ndarray ) \u2013 Input image as a NumPy array. cls ( bool , default: True ) \u2013 Whether to use classification. **kwargs \u2013 Additional arguments passed to the OCR model.","title":"ocr"},{"location":"reference/#mdify.src.ocr.TableRecognizer.process_results","text":"Organizes text into table columns based on bounding box x-coordinates and returns a DataFrame. Ensures every column is populated with either text or None for all rows. Parameters: row_tolerance ( int ) \u2013 Margin of error in pixels to assign elements to the correct row. col_tolerance ( int ) \u2013 Margin of error in pixels to assign elements to the correct column.","title":"process_results"},{"location":"reference/#mdify.src.ocr.TableRecognizer.render","text":"Renders the recognized data onto the input image and saves it. Parameters: img ( ndarray | str ) \u2013 Input image as an array or path. save_full_path ( str ) \u2013 Full path to save the rendered image. font_path ( str , default: '../utils/simfang.ttf' ) \u2013 Path to the font used for rendering. **kwargs \u2013 Additional arguments for rendering.","title":"render"},{"location":"reference/#mdify.src.ocr.TextRecognizer","text":"Bases: OCR Class for recognizing text from images using OCR. Two different models are used for headers and paragraphs as it has been observed that using only one of them for both yields less accurate results. Attributes: paragraph_model_config ( dict ) \u2013 Configuration for paragraph-level OCR. header_reader ( Reader ) \u2013 Reader instance for header-level OCR. det_processor, ( ( det_model , rec_model , rec_processor ) ) \u2013 Components for OCR processing. default_element_type ( str ) \u2013 Default type of element to process ('paragraph').","title":"TextRecognizer"},{"location":"reference/#mdify.src.ocr.TextRecognizer.process_results","text":"Processes OCR results based on the specified element type (paragraph or header). Parameters: element_to_process ( str ) \u2013 either 'header' or 'paragraph'.","title":"process_results"},{"location":"reference/#mdify.src.output","text":"","title":"output"},{"location":"reference/#mdify.src.output.OutputArtifact","text":"Bases: Enum Enum representing the types of artifacts to be saved. Types NONE (int): No artifacts are saved. ONLY_PICTURES (int): Only images are saved. ONLY_TABLES (int): Only tables are saved. ONLY_CHARTS (int): Only charts are saved. ONLY_FORMULAS (int): Only formulas are saved. PICTURES_AND_TABLES (int): Both images and tables are saved. PICTURES_AND_CHARTS (int): Both images and charts are saved. PICTURES_AND_FORMULAS (int): Both images and formulas are saved. TABLES_AND_CHARTS (int): Both tables and charts are saved. TABLES_AND_FORMULAS (int): Both tables and formulas are saved. CHARTS_AND_FORMULAS (int): Both charts and formulas are saved. PICTURES_TABLES_AND_CHARTS (int): Images, tables, and charts are saved. PICTURES_TABLES_AND_FORMULAS (int): Images, tables, and formulas are saved. PICTURES_CHARTS_AND_FORMULAS (int): Images, charts, and formulas are saved. TABLES_CHARTS_AND_FORMULAS (int): Tables, charts, and formulas are saved. ALL (int): All artifacts (images, tables, charts, formulas) are saved.","title":"OutputArtifact"},{"location":"reference/#mdify.src.output.OutputWriter","text":"Handles the process of writing content and optionally saving specified types of artifacts. Methods: write \u2013 str, save_dir: str, filename: str): Writes the content to a file in the specified directory, creating the directory if needed.","title":"OutputWriter"},{"location":"reference/#mdify.src.output.OutputWriter.write","text":"Writes the content to a markdown file in the specified directory. Parameters: content ( str ) \u2013 The content to write to the file. save_dir ( str ) \u2013 Directory where the file will be saved. filename ( str ) \u2013 Name of the file (without extension).","title":"write"},{"location":"reference/#mdify.src.output.WriteMode","text":"Bases: Enum Enum representing the modes for writing content with embedded or referenced artifacts. Modes EMBEDDED (int): Artifacts (e.g., images, tables) are directly embedded in the output content. PLACEHOLDER (int): Placeholders for artifacts are added in the output content, requiring external references. DESCRIBED (int): Artifacts are described textually, without direct embedding or placeholders.","title":"WriteMode"},{"location":"reference/#mdify.src.extractors","text":"","title":"extractors"},{"location":"reference/#mdify.src.extractors.ContentExtractor","text":"Extracts content from a document image based on specified types such as text, tables, pictures, and more. This class delegates extraction tasks to specialized recognizers for text, tables, and pictures. Attributes: text_recognizer ( TextRecognizer ) \u2013 Recognizer for extracting textual elements. table_recognizer ( TableRecognizer ) \u2013 Recognizer for extracting table elements. picture_recognizer ( PictureRecognizer ) \u2013 Recognizer for extracting picture elements.","title":"ContentExtractor"},{"location":"reference/#mdify.src.extractors.ContentExtractor.extract","text":"Method factory that extracts content from the specified image based on the type of element requested. Parameters: image_path ( str ) \u2013 Path to the input image of the document. extract_type ( str ) \u2013 Type of content to extract (e.g., 'text', 'table', 'picture', etc.). **kwargs \u2013 Additional parameters for the specific extraction method. Returns: str ( str ) \u2013 Extracted content as a string.","title":"extract"},{"location":"reference/#mdify.src.utils","text":"","title":"utils"},{"location":"reference/#mdify.src.utils.convert_image_to_pdf","text":"Converts an image file to a PDF. Parameters: image_path ( str ) \u2013 Path to the input image file. pdf_path ( str ) \u2013 Path to save the output PDF file.","title":"convert_image_to_pdf"},{"location":"reference/#mdify.src.utils.convert_to_jpeg","text":"Converts an image to JPEG format. Parameters: im ( Image ) \u2013 The input image. Returns: PIL.Image: The converted image in JPEG format.","title":"convert_to_jpeg"},{"location":"reference/#mdify.src.utils.get_filename","text":"Extracts the filename from a given path. Parameters: path ( str ) \u2013 The full path of the file. include_extension ( bool , default: False ) \u2013 Whether to include the file extension. Defaults to False. Returns: str: The extracted filename.","title":"get_filename"},{"location":"reference/#mdify.src.utils.open_image","text":"Opens an image file or array, converting it to JPEG format if necessary. Parameters: img ( str | ndarray ) \u2013 Path to the image file or an image array. to_numpy ( bool , default: False ) \u2013 Whether to return the image as a NumPy array. Defaults to False. Returns: Union[np.ndarray, PIL.Image]: The opened image.","title":"open_image"},{"location":"usage/","text":"Usage In this page, you will find examples of how to use MDify . 1. Convert a document 1.1 Default parameters This simple code will convert a document into Markdown: from mdify import DocumentParser parser = DocumentParser() parser.parse('PATH_TO_YOUR_DOCUMENT') By default, no artifacts are saved (i.e. tables, charts, etc.). 1.2 Save artifacts If you want to save the artifacts (i.e. tables, charts, etc.), you can use the save_artifacts parameter: from mdify import DocumentParser, OutputArtifact parser = DocumentParser(save_artifacts=OutputArtifact.ALL) parser.parse('PATH_TO_YOUR_DOCUMENT')","title":"Usage"},{"location":"usage/#usage","text":"In this page, you will find examples of how to use MDify .","title":"Usage"},{"location":"usage/#1-convert-a-document","text":"","title":"1. Convert a document"},{"location":"usage/#11-default-parameters","text":"This simple code will convert a document into Markdown: from mdify import DocumentParser parser = DocumentParser() parser.parse('PATH_TO_YOUR_DOCUMENT') By default, no artifacts are saved (i.e. tables, charts, etc.).","title":"1.1 Default parameters"},{"location":"usage/#12-save-artifacts","text":"If you want to save the artifacts (i.e. tables, charts, etc.), you can use the save_artifacts parameter: from mdify import DocumentParser, OutputArtifact parser = DocumentParser(save_artifacts=OutputArtifact.ALL) parser.parse('PATH_TO_YOUR_DOCUMENT')","title":"1.2 Save artifacts"}]}